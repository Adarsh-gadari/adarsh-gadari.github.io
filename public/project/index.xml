<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Hugo Academic CV Theme</title>
    <link>http://localhost:1313/project/</link>
      <atom:link href="http://localhost:1313/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 22 Jun 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_645fa481986063ef.png</url>
      <title>Projects</title>
      <link>http://localhost:1313/project/</link>
    </image>
    
    <item>
      <title>Retinal Layer Segmentation - Boundary vs Mask Labels</title>
      <link>http://localhost:1313/project/retinal-layer-segmentation-boundary-vs-mask-labels/</link>
      <pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/retinal-layer-segmentation-boundary-vs-mask-labels/</guid>
      <description>&lt;!-- ## Mask vs Boundary Label Training: A Comparative Analysis for Retinal Layer Segmentation --&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The spark for this project was ignited by a question that echoed through the research community after my earlier work on weakly supervised retinal layer segmentation: &lt;em&gt;Why generate images with boundary labels instead of the conventional mask-based approach?&lt;/em&gt; This curiosity set the stage for a journey of rigorous experimentation and discovery.&lt;/p&gt;
&lt;h2 id=&#34;experimentation&#34;&gt;Experimentation&lt;/h2&gt;
&lt;p&gt;Determined to find answers, I designed a comprehensive study to compare these two labeling strategies head-to-head. The goal was simple yet ambitious: to empirically test whether boundary-based training could offer tangible advantages over traditional mask-based training, and to see if these benefits would hold across a variety of neural network architectures.&lt;/p&gt;
&lt;p&gt;The experimental process was both challenging and enlightening. I assembled a diverse suite of UNet architectures, ranging from classic designs to deeper, more complex variants. Each model was trained and evaluated under two regimes: one using detailed boundary labels that highlight the edges of retinal layers, and the other using conventional pixel-wise masks. To ensure fairness, every experiment used identical datasets, standardized training protocols, and carefully controlled variables.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;As the results began to emerge, a clear pattern took shape. Boundary-based training consistently outperformed mask-based training across all tested architectures. The models trained on boundaries not only achieved higher subjective scores—especially in capturing fine anatomical details—but also demonstrated more stable and scalable performance, whether in standalone UNets or within adversarial GAN frameworks. Interestingly, while convolutional neural networks are naturally adept at detecting edges due to their differential kernels, achieving high pixel-level accuracy for boundaries remained a nuanced challenge, reflecting the inherent variability in human grading and inviting a better metric than dice score or mean pixel error.&lt;/p&gt;
&lt;p&gt;What made these findings particularly exciting was their architecture-agnostic nature. Whether using a simple UNet or a sophisticated GAN-enhanced model, the benefits of boundary training persisted. This robustness suggested that the approach could be widely adopted, offering practical value for both research and clinical deployment.&lt;/p&gt;
&lt;p&gt;Beyond the technical achievements, this project stands as a testament to the importance of research validation. By proactively addressing questions from the community and designing experiments that go beyond single-model validation, I was able to advance my understanding while supporting real-world applications. The journey from hypothesis to evidence not only deepened my appreciation for experimental rigor but also reinforced the value of curiosity-driven inquiry in shaping the future of medical AI.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This story highlights the evolution from research innovation to research validation, emphasizing the power of thoughtful experimentation and the impact of challenging conventional wisdom in AI-driven medical imaging.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hypergraphs, Neural Networks and explainability</title>
      <link>http://localhost:1313/project/hypergraphs-neural-networks-and-explainability/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/hypergraphs-neural-networks-and-explainability/</guid>
      <description>&lt;h2 id=&#34;details-coming-soon&#34;&gt;Details Coming Soon&lt;/h2&gt;
&lt;h3 id=&#34;thank-you-for-visiting-though&#34;&gt;Thank you for visiting, though!&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Retinal Layer Segmentation</title>
      <link>http://localhost:1313/project/retinal-layer-segmentation/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/retinal-layer-segmentation/</guid>
      <description>&lt;h1 id=&#34;advanced-retinal-layer-segmentation-from-research-innovation-to-commercial-reality&#34;&gt;Advanced Retinal Layer Segmentation: From Research Innovation to Commercial Reality&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The vision for this project was sparked by a pressing need in ophthalmology: how can we make retinal layer segmentation both precise and practical for real-world clinical use? In clinical trials and patient care, accurately segmenting retinal sub-layers is essential for disease monitoring and informed decision-making. Yet, existing methods—whether traditional image processing, graph-based, or deep learning—often falter in real-world settings. Each approach is limited by its dependence on specific data characteristics, and the challenge is compounded by the scarcity of shared datasets and the laborious process of manual annotation.&lt;/p&gt;
&lt;h2 id=&#34;technology&#34;&gt;Technology&lt;/h2&gt;
&lt;p&gt;Determined to overcome these barriers, I set out to bridge the gap between advanced AI research and the everyday needs of clinicians. My journey led me to generative adversarial networks (GANs), whose potential for medical image segmentation was both exciting and promising. By developing a weakly supervised learning strategy that harnessed pseudo-labeling and unlabeled data, I was able to dramatically reduce the reliance on manual annotation. This innovation not only accelerated development but also made the technology more accessible to healthcare providers everywhere.&lt;/p&gt;
&lt;h2 id=&#34;impact&#34;&gt;Impact&lt;/h2&gt;
&lt;p&gt;The platform that emerged from this work is both robust and versatile. At its core is a custom GAN architecture, capable of delivering precise segmentation for both single B-scan images and complex volumetric datasets. This dual capability empowers clinicians to gain quick, actionable insights from individual scans or to conduct comprehensive volumetric analyses for deeper understanding.
Automated reporting features, such as region-wise thickness mapping and export-ready quantitative data, empower clinicians to make informed decisions quickly and confidently. The platform’s outputs meet rigorous medical imaging standards, ensuring reliability in real-world diagnostic settings.&lt;/p&gt;
&lt;h2 id=&#34;deployement&#34;&gt;Deployement&lt;/h2&gt;
&lt;p&gt;Bringing this project from concept to commercial reality/ clinical utility required more than technical innovation. It demanded a holistic understanding of clinical workflows, a commitment to rigorous validation, and a focus on real-world impact. The result is a product that not only advances the state of the art in AI-driven retinal analysis but also demonstrates how research can be translated into practical, life-changing solutions.&lt;/p&gt;
&lt;p&gt;Looking back, this project stands as a testament to the power of interdisciplinary thinking and the importance of bridging research with real-world application.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This story highlights the journey from research to product, emphasizing innovation, collaboration, and real-world impact in medical AI.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Choroid thickness and CVI Calculation</title>
      <link>http://localhost:1313/project/choroid-thickness-and-cvi-calculation/</link>
      <pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/choroid-thickness-and-cvi-calculation/</guid>
      <description>&lt;h1 id=&#34;commercial-choroid-segmentation-from-research-to-clinical-reality&#34;&gt;Commercial Choroid Segmentation: From Research to Clinical Reality&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The journey of developing a comprehensive choroidal analysis platform began with a vision: to bridge the gap between advanced research and real-world clinical needs. Our team set out to create a solution that would not only push the boundaries of AI-powered image analysis but also deliver tangible value to clinicians and patients worldwide.&lt;/p&gt;
&lt;p&gt;Our collaboration with Heidelberg Engineering GmbH, the global leader in OCT imaging technology, was a pivotal moment. Together, we integrated our platform seamlessly into the HEYEX app ecosystem, making sophisticated choroidal imaging analysis accessible to clinicians across the globe. This partnership was more than a technical integration—it was a shared commitment to transforming ophthalmic diagnostics.&lt;/p&gt;
&lt;p&gt;At the heart of our platform lies a suite of advanced AI algorithms, meticulously engineered to deliver precise choroidal thickness measurements and detailed CVI (Choroidal Vascularity Index) mapping. We designed the system to automate what was once a labor-intensive process, reducing analysis time from hours to mere minutes. Clinicians now benefit from standardized, reproducible measurements, enabling consistent patient care regardless of operator or facility.&lt;/p&gt;
&lt;h2 id=&#34;technology&#34;&gt;Technology&lt;/h2&gt;
&lt;p&gt;The technical innovation behind this platform is rooted in a hybrid training methodology. By combining ground truth annotations with pseudo-labeling techniques, we maximized the utility of available data while maintaining rigorous accuracy standards. Our robust approach ensures that the system generalizes well across diverse patient populations, a critical requirement for clinical deployment.&lt;/p&gt;
&lt;p&gt;A key differentiator of our solution is the advanced binarization pipeline. We implemented and optimized state-of-the-art algorithms—Phansalkar, Niblack, and Sauvola—each tailored for specific vessel detection challenges. By systematically combining these techniques, our platform excels at extracting both choriocapillaries and large vessels, providing a comprehensive view of the choroidal vasculature.&lt;/p&gt;
&lt;h2 id=&#34;impact&#34;&gt;Impact&lt;/h2&gt;
&lt;p&gt;The vessel analysis architecture employs multi-scale detection and hierarchical segmentation, enabling simultaneous analysis of capillaries and larger vessels. This, coupled with automated choroidal thickness mapping using the widely adopted ETDRS grid, empowers clinicians to monitor changes over time and correlate findings with various retinal and choroidal pathologies.&lt;/p&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;Engineering excellence was a guiding principle throughout the project. We built an end-to-end solution—from image acquisition to clinical reporting—that is scalable, robust, and optimized for real-time performance. Our team worked closely with Heidelberg’s platform engineers to ensure seamless integration, robust API development, and compliance with stringent data security standards.&lt;/p&gt;
&lt;p&gt;Bringing this platform to market required not only technical expertise but also business acumen. Navigating the complexities of commercial collaboration, regulatory compliance, and global deployment, we transformed a research concept into a production-ready, clinically validated product now serving ophthalmology practices worldwide.&lt;/p&gt;
&lt;p&gt;Looking ahead, the success of this project paves the way for future innovations in AI-driven ophthalmic analysis. It stands as a testament to the power of academic-industry collaboration and the impact that thoughtful, well-engineered technology can have on clinical practice. Our journey from research to commercial reality continues to inspire us to push boundaries and redefine what’s possible in medical imaging.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This project demonstrates the successful transition from research innovation to commercial reality, showcasing expertise in advanced AI development, clinical application design, and industry partnership management.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
