<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative AI | Adarsh Gadari</title>
    <link>http://localhost:1313/tags/generative-ai/</link>
      <atom:link href="http://localhost:1313/tags/generative-ai/index.xml" rel="self" type="application/rss+xml" />
    <description>Generative AI</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 22 Jun 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_645fa481986063ef.png</url>
      <title>Generative AI</title>
      <link>http://localhost:1313/tags/generative-ai/</link>
    </image>
    
    <item>
      <title>Retinal Layer Segmentation - Boundary vs Mask Labels</title>
      <link>http://localhost:1313/project/retinal-layer-segmentation-boundary-vs-mask-labels/</link>
      <pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/retinal-layer-segmentation-boundary-vs-mask-labels/</guid>
      <description>&lt;!-- ## Mask vs Boundary Label Training: A Comparative Analysis for Retinal Layer Segmentation --&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The spark for this project was ignited by a question that echoed through the research community after my earlier work on weakly supervised retinal layer segmentation: &lt;em&gt;Why generate images with boundary labels instead of the conventional mask-based approach?&lt;/em&gt; This curiosity set the stage for a journey of rigorous experimentation and discovery.&lt;/p&gt;
&lt;h2 id=&#34;experimentation&#34;&gt;Experimentation&lt;/h2&gt;
&lt;p&gt;Determined to find answers, I designed a comprehensive study to compare these two labeling strategies head-to-head. The goal was simple yet ambitious: to empirically test whether boundary-based training could offer tangible advantages over traditional mask-based training, and to see if these benefits would hold across a variety of neural network architectures.&lt;/p&gt;
&lt;p&gt;The experimental process was both challenging and enlightening. I assembled a diverse suite of UNet architectures, ranging from classic designs to deeper, more complex variants. Each model was trained and evaluated under two regimes: one using detailed boundary labels that highlight the edges of retinal layers, and the other using conventional pixel-wise masks. To ensure fairness, every experiment used identical datasets, standardized training protocols, and carefully controlled variables.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;As the results began to emerge, a clear pattern took shape. Boundary-based training consistently outperformed mask-based training across all tested architectures. The models trained on boundaries not only achieved higher subjective scores—especially in capturing fine anatomical details—but also demonstrated more stable and scalable performance, whether in standalone UNets or within adversarial GAN frameworks. Interestingly, while convolutional neural networks are naturally adept at detecting edges due to their differential kernels, achieving high pixel-level accuracy for boundaries remained a nuanced challenge, reflecting the inherent variability in human grading and inviting a better metric than dice score or mean pixel error.&lt;/p&gt;
&lt;p&gt;What made these findings particularly exciting was their architecture-agnostic nature. Whether using a simple UNet or a sophisticated GAN-enhanced model, the benefits of boundary training persisted. This robustness suggested that the approach could be widely adopted, offering practical value for both research and clinical deployment.&lt;/p&gt;
&lt;p&gt;Beyond the technical achievements, this project stands as a testament to the importance of research validation. By proactively addressing questions from the community and designing experiments that go beyond single-model validation, I was able to advance my understanding while supporting real-world applications. The journey from hypothesis to evidence not only deepened my appreciation for experimental rigor but also reinforced the value of curiosity-driven inquiry in shaping the future of medical AI.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This story highlights the evolution from research innovation to research validation, emphasizing the power of thoughtful experimentation and the impact of challenging conventional wisdom in AI-driven medical imaging.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Retinal Layer Segmentation</title>
      <link>http://localhost:1313/project/retinal-layer-segmentation/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/retinal-layer-segmentation/</guid>
      <description>&lt;h1 id=&#34;advanced-retinal-layer-segmentation-from-research-innovation-to-commercial-reality&#34;&gt;Advanced Retinal Layer Segmentation: From Research Innovation to Commercial Reality&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The vision for this project was sparked by a pressing need in ophthalmology: how can we make retinal layer segmentation both precise and practical for real-world clinical use? In clinical trials and patient care, accurately segmenting retinal sub-layers is essential for disease monitoring and informed decision-making. Yet, existing methods—whether traditional image processing, graph-based, or deep learning—often falter in real-world settings. Each approach is limited by its dependence on specific data characteristics, and the challenge is compounded by the scarcity of shared datasets and the laborious process of manual annotation.&lt;/p&gt;
&lt;h2 id=&#34;technology&#34;&gt;Technology&lt;/h2&gt;
&lt;p&gt;Determined to overcome these barriers, I set out to bridge the gap between advanced AI research and the everyday needs of clinicians. My journey led me to generative adversarial networks (GANs), whose potential for medical image segmentation was both exciting and promising. By developing a weakly supervised learning strategy that harnessed pseudo-labeling and unlabeled data, I was able to dramatically reduce the reliance on manual annotation. This innovation not only accelerated development but also made the technology more accessible to healthcare providers everywhere.&lt;/p&gt;
&lt;h2 id=&#34;impact&#34;&gt;Impact&lt;/h2&gt;
&lt;p&gt;The platform that emerged from this work is both robust and versatile. At its core is a custom GAN architecture, capable of delivering precise segmentation for both single B-scan images and complex volumetric datasets. This dual capability empowers clinicians to gain quick, actionable insights from individual scans or to conduct comprehensive volumetric analyses for deeper understanding.
Automated reporting features, such as region-wise thickness mapping and export-ready quantitative data, empower clinicians to make informed decisions quickly and confidently. The platform’s outputs meet rigorous medical imaging standards, ensuring reliability in real-world diagnostic settings.&lt;/p&gt;
&lt;h2 id=&#34;deployement&#34;&gt;Deployement&lt;/h2&gt;
&lt;p&gt;Bringing this project from concept to commercial reality/ clinical utility required more than technical innovation. It demanded a holistic understanding of clinical workflows, a commitment to rigorous validation, and a focus on real-world impact. The result is a product that not only advances the state of the art in AI-driven retinal analysis but also demonstrates how research can be translated into practical, life-changing solutions.&lt;/p&gt;
&lt;p&gt;Looking back, this project stands as a testament to the power of interdisciplinary thinking and the importance of bridging research with real-world application.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;This story highlights the journey from research to product, emphasizing innovation, collaboration, and real-world impact in medical AI.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
